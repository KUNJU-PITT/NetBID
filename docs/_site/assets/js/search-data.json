{
  "0": {
    "id": "0",
    "title": "Advanced analysis",
    "content": "Advanced analysis Part I: for top drivers I.1: volcano plot for DE/DA, p-value Vs. fold-change I.2: Heatmap for top drivers I.3: Function enrichment plot for top drivers I.4: Bubble plot for top drivers I.5: GSEA plot for top driver Part II: for each driver II.1: GSEA plot for each driver II.2: target network structure for each driver, or two drivers (overlap testing) II.3: category plot for the expression/activity for each driver Part III: advanced plots III.1: input driver and target, get shortest path and draw subnetwork III.2: gene set-based activity analysis, including vocalno, heatmap, category and GSEA plot III.3: SINBA plot for synergistic effect Part IV: Supplementary usage for different conditions IV.1: if want to get mean expression/activity value for each phenotype cluster",
    "url": "http://localhost:4000/docs/advanced_analysis",
    "relUrl": "/docs/advanced_analysis"
  },
  "1": {
    "id": "1",
    "title": "Driver estimation",
    "content": "Driver estimation Step1: load in gene expression datasets for analysis (exp-load,exp-cluster,exp-QC) Step2: activity calculation (act-prep,act-get) Step3: get DE/DA (act-DA) Step4: generate master table (ms-tab)",
    "url": "http://localhost:4000/docs/driver_estimation",
    "relUrl": "/docs/driver_estimation"
  },
  "2": {
    "id": "2",
    "title": "NetBID2",
    "content": "NetBID2: Network-based Bayesian Inference of Drivers. Version 2 This is the documentation for the usage of NetBID2. Get started now View it on GitHub Overview NetBID is a systems biology tool called data-driven network-based Bayesian inference of drivers, by integrating data from transcriptomics,proteomics and phosphoproteomics. The drivers could be transcription facotrs (TF) or signaling factors (SIG). NetBID2 is the second version of NetBID, which not only covers the main functions of NetBID, but also provides plenty of supporting functions and suggested workflow to finish a NetBID2-based analysis: Provide data processing functions to assist Expression matrix pre-processing and quality assessment SJAracne-based network construction Activity calculation for drivers and gene sets Estimation of differentiated expressed genes or differentiated activated drivers Generation of master table for drivers Provide visualization functions to assist Unsupervised clustering for samples and comparison with known labels Display of a list of interested drivers, the profile of the significance and the feature of the target genes Display of a specific driver, the profile of the significance, the feature of the target genes and the detailed network structure Provide supporting functions to assist Gene/transcript ID conversion Gene function enrichment analysis &amp; result visualization Data and pipeline management Getting started Dependencies R, version &gt;= 3.4.0 Pre-request R packages Quick start: install R packages (NetBID2) install the R packages from github (not published yet) library(devtools) install_github(&quot;jyyulab/NetBID-dev&quot;,ref=&#39;master&#39;) OR, download the released source package from NetBID2_0.1.1.tar.gz and local install install.packages(&#39;NetBID2_0.1.1.tar.gz&#39;,repos=NULL) Design manual The manual for all functions in NetBID2 could be obtained from NetBID2_0.1.1.pdf. All functions have the demo scripts. All 67 invokable functions could be grouped as shown in the figure below: NetBID2 has four functions focusing on suggested pipeline (not required): NetBID.network.dir.create() will generate a working directory structure for the network generation part in NetBID2. This function aims to assist researchers to organize the working directory. NetBID.analysis.dir.create() will generate a working directory structure for the driver analysis part in NetBID2. This function aims to assist researchers to organize the working directory. NetBID.saveRData() save the dataset of one designated step the step into file. NetBID.loadRData() load the dataset of one designated step from file. Users could save two complicate list object, network.par in the network generation part and analysis.par in the driver analysis part, into the data directory (network.par$out.dir.DATA or analysis.par$out.dir.DATA), with the name of the RData marked by step name. The two lists could make user to save the whole related dataset in each step NetBID.saveRData() and easy to get them back by using NetBID.loadRData(). The RData saved from each step could be used to run the following analysis without repeating the former steps. The pipeline steps are suggested in the figure below with detailed component for the list object in the final step in the two parts: Strongly suggest new users to follow the pipeline to manage the analysis project. The pipeline is included in the tutorial below. User could follow the demo in the tutorial for better understanding the design. Most of the functions in NetBID2 are not strictly dependent on the pipeline object, user could try to learn the usage of each function by running the example in each function and prepare the required input by themselves. Tutorial We choose the demo dataset from GEO database: GSE116028. This dataset contains microarray data for 13 adult medulloblastoma (MB) samples. Three subgroups of adult MB were identified by distinct expression profiles, clinical features, pathological features, and prognosis, including 3 SHH, 4 WNT, and 6 Group4. From them, Group4 tumors had significantly worse progression-free and overall survival compared with tumors of the other molecular subtypes. Here, we want to find potential hidden drivers in Group4 compared with the other subtypes by using NetBID2, for which may be related with the specific clinical feature for Group4 MB. Though the dataset in the tutorial is microarray, we will include the usage of processing RNASeq dataset in each step. The tutorials are divided by three ordered and relatively independent parts as follows: Network generation Driver estimation Advanced analysis About the project For the detailed description of NetBID algorithm, please refer our lab page View Yu Lab@St. Jude. License Distributed by an MIT license.",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "3": {
    "id": "3",
    "title": "Network generation",
    "content": "Network Generation The purpose for the first part: generate a gene regulatory network based on a transcriptomic datasets. The full demo script for this part could be found in pipeline_network_demo1.R. Step0: preparations Before start, we need to library the installed NetBID2. # library the package library(NetBID2) This tutorial is based on the suggested pipeline design in NetBID2. So, we need to set up a main directory for the project in project_main_dir. The main directory could have multiple projects under the path, separeted by the project_name as the name for the sub-directory. So user could use the same main directory for another project. But project related files with the same project_main_dir and project_name will be covered. So, in the script below, user could add a time tag in the project_name to avoid this by accident. #set up paramters project_main_dir &lt;- &#39;test/&#39; ### user defined main directory for the project, one main directory could have multiple projects, separeted by project name current_date &lt;- format(Sys.time(), &quot;%Y-%m-%d&quot;) ## current date for project running, suggested to add the time tag project_name &lt;- sprintf(&#39;project_%s&#39;,current_date) ## project name for the project Once decided the project_main_dir and project_name, user could run NetBID.network.dir.create() to generate the sub-directories for the working directory, including QC/ to save QC related files, DATA/ to save RData and SJAR/ to save data for running SJARACNe. Besides, a global list variable network.par will be returned by the function. Attention, if the current environment already has this variable, the function will do nothing, report a warning message and return the original network.par. ## network.par is very essential in the analysis, if the environment already has this parameter, strongly suggest to delete it first network.par &lt;- NetBID.network.dir.create(project_main_dir=project_main_dir,prject_name=project_name) ## create working directory Step1: load in gene expression datasets for network construction (exp-load) Here, we use the dataset from GEO database as the demo that we could directly download it from web by input the GSE ID and GPL ID. If set getGPL=TRUE, will download the gene annotation file. The output of this function will be the eSet class object and will save the RData into out.dir. Next time by running this function, it will try to load the RData in the out.dir/{GSE}_{GPL}.RData first (if update=FALSE). # from GEO, need to provide GSE and GPL net_eset &lt;- load.exp.GEO(out.dir=network.par$out.dir.DATA,GSE=&#39;GSE116028&#39;,GPL=&#39;GPL6480&#39;,getGPL=TRUE,update=FALSE) Optional: User could choose to update the feature data frame in the eSet object by update_eset.feature(). This function allows user to change the main ID from from_feature to to_feature by inputting the transfer table use_feature_info and choosing the merge_method. # ID conversion, or merge transcript level to expression level, use_feature_info can be other dataframe info; optional; net_eset &lt;- update_eset.feature(use_eset=net_eset,use_feature_info=fData(net_eset),from_feature=&#39;ID&#39;,to_feature=&#39;GENE_SYMBOL&#39;,merge_method=&#39;median&#39;) ### !!! need modify Optional: User could choose to update the phenotype data frame in the eSet object by update_eset.phenotype(). This function allows user to get phenotype information from the data frame use_phenotype_info by indicating the column that matched the sample name. The use_col could be used to tell the function which column in use_phenotype_info will be kept. If set to ‘auto’, wil extract columns with unique sample feature ranges from 2 to sample size-1. If set to ‘GEO-auto’, will extract columns: ‘geo_accession’,’title’,’source_name_ch1’,and columns end with ‘:ch1’. # select phenotype columns or user add phenotype info; optional net_eset &lt;- update_eset.phenotype(use_eset=net_eset,use_phenotype_info=pData(net_eset),use_sample_col=&#39;geo_accession&#39;,use_col=&#39;GEO-auto&#39;) Now, we need to check the data quality of the eSet by draw.eset.QC(). The QC report html mainly contains four parts, heatmap, pca, density and meansd. The intgroup could be used to indicate which column from the fData(eset) will be used in the plot (heatmap, pca, density). If set to NULL, will automatcially extract all possible groups by get_int_group(). For the usage of draw.eset.QC, pandoc is required for generate_html=TRUE. If pandoc_available()=FALSE, please install pandoc and set environment of pandoc by Sys.setenv(RSTUDIO_PANDOC=installed path). # QC for the raw expdatasets # if intgroup==NULL, will auto get intgroup # prefix: prefix for the pdf files draw.eset.QC(network.par$net.eset,outdir=network.par$out.dir.QC,intgroup=NULL,do.logtransform=FALSE,prefix=&#39;beforeQC_&#39;) What to check for the QC report html before_QC.html ? The number of samples and genes (probes/transcripts/…); All samples will be clustered by the expression pattern from all genes, check possible mis-labeled samples; The density plots show the range and distribution for the expression values, may judge whether the original dataset has been log transformed; The meansd plots show the relationship between the mean and standard deviation of the genes, used to verify whether there is a dependence of the standard deviation (or variance) on the mean. Now, basic processing steps are finished for the input expression dataset. Save it to network.par. # add the variable into network.par, very essential ! network.par$net.eset &lt;- net_eset Save network.par into the RData file and give the step name to it, e.g exp-load. The RData could be found in network.par$out.dir.DATA/network.par.Step.{exp-load}.RData. # save to RData NetBID.saveRData(network.par = network.par,step=&#39;exp-load&#39;) Input RNASeq dataset Another two functions can be applied to load expression dataset from RNASeq, load.exp.RNASeq.demo() and load.exp.RNASeq.demoSalmon(). BUT this two function are just demo functions, which do not support complicated options in tximport() and DESeq(). Besides, the output format may be different by using different dataset as reference that these two load functions may not work well. Suggest to use the original functions if have some experience of coding. If try to use load.exp.RNASeq.demo() and load.exp.RNASeq.demoSalmon(), be ATTENTION to the return_type option in the functions. ‘txi’ is the output of tximport(), a simple list containing matrices: abundance, counts, length. ‘counts’ is the output of raw count matrix. ‘tpm’ is the output of raw tpm. ‘dds’ is the DESeqDataSet class object, the data has been processed by DESeq(). ‘eset’ is the ExpressionSet class object, the expression data matrix has been processed by DESeq(), vst(). Default is ‘eset’. If user do not choose ‘eset’, the output will not be directly used in the following scripts in the tutorial. Check the Input expression matrix section below. Input expression matrix If the user decide to prepare the expression matrix by themselves. The eSet object could be directly obtained by using generate.eset(). For example for RNASeq dataset with ‘tpm’ as the output: #tpm &lt;- load.exp.RNASeq.demo(XXX) tmp_mat &lt;- log2(tpm) tmp_eset &lt;- generate.eset(exp_mat = tmp_mat, phenotype_info = NULL,feature_info = NULL, annotation_info = &quot;&quot;) For the option of generate.eset(), if phenotype_info = NULL, a one column named with ‘group’ will be automatically generated. if feature_info = NULL, a one column named with ‘gene’ will be automatically generated. Step2: normalization for the expression dataset (exp-QC) Before start, load the RData from the previous step if user want to re-run the following steps or re-open the R session. Remember to set the temporary network.par if re-open the R session and network.par$out.dir.DATA will be used to find the correct RData file. No need to run this if continue working from the previous step. # load from RData #network.par &lt;- list() #network.par$out.dir.DATA &lt;- &#39;test//project_2019-05-02//DATA/&#39; NetBID.loadRData(network.par = network.par,step=&#39;exp-load&#39;) Following basic QC steps are suggested procedure for microarray dataset, all of the steps are optional. Firstly, check the NA values in the expression dataset by counting the number of NA values for each sample and for each gene (or probes/transcripts/…). If one sample or gene with too many NA values, user could choose to remove that gene or sample or do imputation by impute.knn(). ## following QC steps are optional !!!! mat &lt;- exprs(network.par$net.eset) # remove possible NA? or imputation ? ## need to user-decide sample_na_count &lt;- apply(mat,1,function(x){length(which(is.na(x)==TRUE))}) print(table(sample_na_count)) gene_na_count &lt;- apply(mat,2,function(x){length(which(is.na(x)==TRUE))}) print(table(gene_na_count)) if(sum(sample_na_count)+sum(gene_na_count)&gt;0) mat &lt;- impute.knn(mat)$data Secondly, the log2 transformation. Sometimes it is hard to know whether the original dataset has been log2 transformed or not. Here, we provide an experienced judging threshold for the median value. This is may not be suitable for all conditions. # log2 transformation med_val &lt;- median(apply(mat,2,median));print(med_val) if(med_val&gt;16){mat &lt;- log2(mat)} Thirdly, the quantile normalization between samples. This is suggested for dealing with microarray dataset and not for RNASeq, even the log2tpm etc. # quantile normalization mat &lt;- normalizeQuantiles(mat) ## limma quantile normalization Fourthly, remove low expressed genes across nearly all samples. The suggested threshold is shown below, try to remove genes that in more than 90% samples, the expression value is lower than 5%. # remove low expressed genes, such as whether in more than 90% samples, the expression value is lower than 5% choose1 &lt;- apply(mat&lt;= quantile(mat, probs = 0.05), 1, sum)&lt;= ncol(mat) * 0.90 print(table(choose1)) mat &lt;- mat[choose1,] Now, the expression matrix has been updated, need to save into the eSet class object by using generate.eset(). Update the network.par$net.eset, generate the QC report html by draw.eset.QC() and save to RData by NetBID.saveRData(). # update eset net_eset &lt;- generate.eset(exp_mat=mat, phenotype_info=pData(network.par$net.eset)[colnames(mat),], feature_info=fData(network.par$net.eset)[rownames(mat),], annotation_info=annotation(network.par$net.eset)) network.par$net.eset &lt;- net_eset draw.eset.QC(network.par$net.eset,outdir=network.par$out.dir.QC,intgroup=NULL,do.logtransform=FALSE,prefix=&#39;afterQC_&#39;) # save to RData NetBID.saveRData(network.par = network.par,step=&#39;exp-QC&#39;) What to check for the QC report html after QC steps after_QC.html? The number of samples and genes (probes/transcripts/…), whether large amount of genes/samples are removed; All samples will be clustered by the expression pattern from all genes, check possible mis-labeled samples; The density plots show the range and distribution for the expression values, whether the low expressed genes have been removed; The meansd plots show the relationship between the mean and standard deviation of the genes, used to verify whether there is a dependence of the standard deviation (or variance) on the mean. QC for RNASeq dataset No matter what strategy is used to input the RNASeq dataset, only the fourth step ‘remove low expressed genes’ is suggested. For example, if use load.exp.RNASeq.demo() or load.exp.RNASeq.demoSalmon() and output dds, no previous normlization is required. If user use the raw count as the expression matrix, the RNASeqCount.normalize.scale() could be used to normalize the count data, followed by ‘log2 transformation’. For the fpkm(Fragments per kilobase of exon per million reads mapped ), tpm(Transcripts Per Million), cpm(Counts Per Million), the second step ‘log2 transformation’ is suggested. User is strongly suggested to judge which QC step to use for their own dataset or follow the pipeline suggested by the different calling software. Combine two datasets If user want to combine two datasets, merge_eset() could be used. If the original two datasets are generated from the same platform with the same expression gene list, no Z-transformation will be performed; otherwise Z-transformation will be performed before merging the dataset. The merged eSet will automatically generate one phenotype column named by group_col_name. By default, the function will not remove batches between the two datasets. Strongly suggest to remove the batch for microarray dataset but not for RNASeq dataset. For the RNASeq dataset, user could follow the tutorial in the Step3 for detailed sample clustering checking and re-run the code in this step. Step3: check sample cluster information, optional (exp-cluster) Before start, load the RData from the previous step if user want to re-run the following steps or re-open the R session. Remember to set the temporary network.par if re-open the R session and network.par$out.dir.DATA will be used to find the correct RData file. No need to run this if continue working from the previous step. # load from RData #network.par &lt;- list() #network.par$out.dir.DATA &lt;- &#39;test//project_2019-05-02//DATA/&#39; NetBID.loadRData(network.par = network.par,step=&#39;exp-QC&#39;) Select the most variable genes for the sample clustering analysis by IQR.filter(). In the script below, the most 50% variable genes will be used. For the IQR.filter() function, it allows user to input a list of genes (loose_gene), which can be applied to loose_thre. This is applicable when user need to keep more interested genes (e.g transcription factors) by using a looser threshold for filteration. # use most variable genes for cluster mat &lt;- exprs(network.par$net.eset) choose1 &lt;- IQR.filter(exp_mat=mat,use_genes=rownames(mat),thre = 0.5,loose_gene=NULL,loose_thre=0.1) print(table(choose1)) mat &lt;- mat[choose1,] Generate a temporary eSet and get the html QC report Cluster_QC.html. Here give a first galance of sample clustering results Vs. pre-defined sample groups. # generate tmp eset tmp_net_eset &lt;- generate.eset(exp_mat=mat, phenotype_info=pData(network.par$net.eset)[colnames(mat),], feature_info=fData(network.par$net.eset)[rownames(mat),], annotation_info=annotation(network.par$net.eset)) # QC plots draw.eset.QC(tmp_net_eset,outdir=network.par$out.dir.QC,intgroup=NULL,do.logtransform=FALSE,prefix=&#39;Cluster_&#39;) In the following scripts, user could get lots of plots. Firstly, get the phenotype information data frame pData(network.par$net.eset) and all possible phenotype classes intgroup. For each intgroup, use could choose to use draw.pca.kmeans() or draw.umap.kmeans() to display the sample clustering results between the observed label and predicted label. The prediction is performed by kmeans based on pca or umap dimension reduction results. If user use MICA for clustering, draw.MICA() also could be used for result display. The output for those functions will be the predicted label for the best k if setting return_type=&#39;optimal&#39; or the results for all_k if return_type=&#39;all&#39;. # more cluster functions (will not directly save to file, but actively layout) phe &lt;- pData(network.par$net.eset) intgroup &lt;- get_int_group(network.par$net.eset) # pca+kmeans in 2D for(i in 1:length(intgroup)){ print(intgroup[i]) pred_label &lt;- draw.pca.kmeans(mat=mat,all_k = NULL,obs_label=get_obs_label(phe,intgroup[i])) } Take subgroup as an example, the following scripts will generate: use_int &lt;- &#39;subgroup&#39; pred_label &lt;- draw.pca.kmeans(mat=mat,all_k = NULL,obs_label=get_obs_label(phe,use_int),plot_type=&#39;2D&#39;) This is the basic scatter plot to display the samples with color coded by observed and predicted label. The statistics in the right figure is the score between predicted label and observed label by get_clustComp(). ARI stands for ‘adjusted rand index’, which ranges from 0 to 1 with higher value indicates higher similarity. pred_label &lt;- draw.pca.kmeans(mat=mat,all_k = NULL,obs_label=get_obs_label(phe,use_int),plot_type=&#39;2D.ellipse&#39;) This is the scatter plot with ellipse to cover the points belong to one class. pred_label &lt;- draw.pca.kmeans(mat=mat,all_k = NULL,obs_label=get_obs_label(phe,use_int),plot_type=&#39;2D.text&#39;) This is the scatter plot with sample name directly labelled on the plot, which is useful for outlier checking. pred_label &lt;- draw.pca.kmeans(mat=mat,all_k = NULL,obs_label=get_obs_label(phe,use_int),plot_type=&#39;3D&#39;) This is the 3D scatter plot. print(table(list(pred_label=pred_label,obs_label=get_obs_label(phe, use_int)))) draw.clustComp(pred_label,obs_label=get_obs_label(phe,use_int),outlier_cex=1,low_K=10) ## display the comparison in detail This is the table to display the detailed difference between predicted label and observed label. We can see from the table here, 4 WNTs are further separated into two groups. In this demo dataset, no clear outlier samples are observed. If user find some somes need to remove, please remove the samples and re-run the exp-QC steps. Step4: prepare SJARACNE (sjaracne-prep) Before start, load the RData from the ‘exp-QC’ step if user want to re-run the following steps or re-open the R session. Remember to set the temporary network.par if re-open the R session and network.par$out.dir.DATA will be used to find the correct RData file. No need to run this if continue working from the previous step. # load from RData #network.par &lt;- list() #network.par$out.dir.DATA &lt;- &#39;test//project_2019-05-02//DATA/&#39; NetBID.loadRData(network.par = network.par,step=&#39;exp-QC&#39;) Load the transcription facotrs (TF) and signaling factors (SIG) list from database by db.preload().NetBID2 has prepared both ‘gene’ and ‘transcript’ level RData files for human. If user’s input is not human, could run db.preload() to prepare the database files. If leave main.dir=NULL, the RData will be saved to system.file(package = &quot;NetBID2&quot;)/db/. If NetBID2 is installed in a public place with no permission to user, just set main.dir to another place and remember to use the same path next time using it. For the TF and SIG list, NetBID2 has provided the files in ‘external_gene_name’ and ‘ensembl_gene_id’ ID type for human and mouse. (e.g MOUSE_SIG_ensembl_gene_id.txt in system.file(package = &quot;NetBID2&quot;)/db/). The function will automatically use those files if set TF_list=NULL or SIG_list=NULL. User could also input their own list and input by setting TF_list or SIG_list. # load database db.preload(use_level=&#39;gene&#39;,use_spe=&#39;human&#39;,update=FALSE) After loading the database, user need to set the ID attribute type use_gene_type for the input expression matrix. Check ID conversion section below for detailed description of ID conversion issue. # ID convertion, get TF/SIG list !!!! use_gene_type &lt;- &#39;external_gene_name&#39; ## this should user-defined !!! use_genes &lt;- rownames(fData(network.par$net.eset)) use_list &lt;- get.TF_SIG.list(use_genes,use_gene_type=use_gene_type) The above two steps are not required if user could get the TF_list and SIG_list with the same ID type as the expression matrix, just input in the SJAracne.prepare(). The final step is to prepare the input for running SJAracne. User could choose to use part of the samples or use all. The IQR.thre and IQR.loose_thre will be passed to IQR.filter(). The loose_gene in this function will be the genes in TF_list and SIG_list as we want to keep more possible drivers in the network generation. # select sample for analysis phe &lt;- pData(network.par$net.eset) use.samples &lt;- rownames(phe) ## use all samples, or choose to use some samples prj.name &lt;- network.par$project.name # can use other names, if need to run different use samples SJAracne.prepare(eset=network.par$net.eset,use.samples=use.samples, TF_list=use_list$tf,SIG_list=use_list$sig, IQR.thre = 0.5,IQR.loose_thre = 0.1, SJAR.project_name=prj.name,SJAR.main_dir=network.par$out.dir.SJAR) Next is to follow the message to run SJAracne. As SJAracne will consume lots of memory in running, which may be not suitable in R session, user need to follow the instructions to run SJAracne. ID conversion We will use the ID name from biomaRt. Some common attribute names are ‘ensembl_transcript_id’, ‘ensembl_gene_id’, ‘external_transcript_name’, ‘external_gene_name’, ‘hgnc_symbol’, ‘entrezgene’, ‘refseq_mrna’. If the original input is ‘ensembl_gene_id_version’ or ‘ensembl_transcript_id_version’, user could set ignore_version=TRUE to neglect the version number. ATTENTION! biomaRt will use the newest version number of GENCODE and all the ID conversion related functions db.preload(), get.TF_SIG.list(), get_IDtransfer(), get_IDtransfer2symbol2type(), get_IDtransfer_betweenSpecies() will remotely call the database from biomaRt through the web link. So, the version number may be different when running the same code at different time. get_IDtransfer(), get_IDtransfer2symbol2type(), get_IDtransfer_betweenSpecies() will output a transfer table used for get_name_transfertab(). User could use their curated one. Finish network generation part !!! Cheers !!!",
    "url": "http://localhost:4000/docs/network_generation",
    "relUrl": "/docs/network_generation"
  },
  "4": {
    "id": "4",
    "title": "Pre-requested",
    "content": "Pre-requested R packages R version &gt;= 3.4.0 The package is developed on R 3.5.1, and has been tested on 3.4.0. Following is the description for dependent R packages, mainly for developers to better understand the code in NetBID2. Users do not need to digest the information below. R package Functions1 Category Purpose Biobase - Data processing ExpressionSet class GEOquery getGEO Data processing Get expression dataset from GEO database limma - Data processing Expression data normalization impute impute.knn Data processing Data imputation tximport Data processing Data import   DESeq2 DESeqDataSetFromTximport,DESeq Data processing Data import from txi and normalization for RNASeq data ConsensusClusterPlus - Clustering Get consensus clustering results aricode clustComp Clustering For cluster comparison statistic calculation igraph - Visualization Igraph class and basic network-based calculation RColorBrewer brewer.pal Visualization Get color bar plot3D scatter3D Visualization 3D plot plotrix draw.ellipse Visualization drawing ellipse umap umap Visualization data dimension reduction and visualization vsn meanSdPlot Visualization meansd plot hexbin hexbin Visualization meansd plot ComplexHeatmap Heatmap Visualization heatmap drawing ordinal clm,clmm bid Cumulative Link Mixed Models MCMCglmm MCMCglmm bid Multivariate Generalized Linear Mixed Models arm bayesglm bid Bayesian generalized linear models reshape melt bid Melt an object into a form suitable for easy casting biomaRt - ID conversion ID conversion GSVA gsva Gene Set gene set activity calculation msigdbr - Gene Set MSigDB database openxlsx - IO Output into excel file (master table) rhdf5 H5Fopen,H5Fclose IO For hd5 formation data processing (MICA) rmarkdown render Report For generating html report file kableExtra - Report For table layout in the report file ’-‘ in the Function column represents multiple functions in the package were used in NetBID2. &#8617;",
    "url": "http://localhost:4000/docs/pre_request",
    "relUrl": "/docs/pre_request"
  }
  
}
